{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "import statistics\n",
    "from sklearn.metrics import roc_curve,auc,precision_recall_curve,confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69972, 22)\n"
     ]
    }
   ],
   "source": [
    "diabetes=pd.read_csv(r'C:\\Users\\ADMIN\\Desktop\\Diabetes_copy.csv')\n",
    "\n",
    "diabetes = pd.DataFrame(diabetes)\n",
    "\n",
    "print(diabetes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69972,)\n",
      "0    1\n",
      "1    2\n",
      "2    2\n",
      "3    2\n",
      "4    1\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "diabetes['readmitted']= label_encoder.fit_transform(diabetes['readmitted']) \n",
    "print(diabetes['readmitted'].shape)\n",
    "print(diabetes['readmitted'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset in features and target variable\n",
    "feature_cols = ['race','gender','age','admission_type_id','discharge_disposition_id','admission_source_id','time_in_hospital','medical_specialty','num_lab_procedures','num_procedures','num_medications','number_outpatient','number_emergency','number_inpatient', 'diag_1','number_diagnoses','max_glu_serum','insulin','A1Cresult','change','diabetesMed']\n",
    "X = diabetes[feature_cols] # Features\n",
    "y = diabetes.readmitted # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69972, 53)\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X,drop_first=True)\n",
    "print(X.shape)\n",
    "X = X\n",
    "Y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined unlabelling function\n",
    "\n",
    "import random\n",
    "\n",
    "def maskfunc(true_target, percentage):\n",
    "    if (percentage >=0 and percentage <= 100):\n",
    "       \n",
    "        n_total_samples = len(true_target)\n",
    "        unlabel = (100-percentage)\n",
    "        n_labeled_points = int((unlabel * len(y))/100)\n",
    "        indices = np.arange(n_total_samples)\n",
    "        unlabeled_set = indices[n_labeled_points:]\n",
    "        \n",
    "        labels = true_target.copy()\n",
    "        labels[unlabeled_set] = -1\n",
    "        \n",
    "        return labels,unlabeled_set\n",
    "    else: \n",
    "        return 'Percentage not in range of (0,100)'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report(unlabeled_set_value, percen):\n",
    "    unlabeled_set = unlabeled_set_value\n",
    "    predicted_labels = label_prop_model.transduction_[unlabeled_set]\n",
    "    true_labels = Y[unlabeled_set]\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=label_prop_model.classes_)\n",
    "    print('Classifcation report \\n')\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    " \n",
    "\n",
    "    print('Confusion matrix \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report_spread(unlabeled_set_value, percen):\n",
    "    unlabeled_set = unlabeled_set_value\n",
    "    predicted_labels = label_prop_model.transduction_[unlabeled_set]\n",
    "    true_labels = Y[unlabeled_set]\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=label_prop_model.classes_)\n",
    "    print('Classifcation report \\n')\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    " \n",
    "\n",
    "    print('Confusion matrix \\n',cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=8, max_iter=100, gamma=20,n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 100 % labelled data\t 0.6453\n"
     ]
    }
   ],
   "source": [
    "# 100% labelled data\n",
    "label_prop_model.fit(X, Y)\n",
    "score_zero = label_prop_model.score(X, Y)\n",
    "print('Accuracy with 100 % labelled data\\t',round(score_zero,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.05      0.07       384\n",
      "           1       0.22      0.34      0.27      1323\n",
      "           2       0.78      0.70      0.74      5291\n",
      "\n",
      "    accuracy                           0.60      6998\n",
      "   macro avg       0.37      0.36      0.36      6998\n",
      "weighted avg       0.63      0.60      0.61      6998\n",
      "\n",
      "Confusion matrix \n",
      " [[  18  126  240]\n",
      " [  44  451  828]\n",
      " [ 103 1471 3717]]\n"
     ]
    }
   ],
   "source": [
    "# 90% labelled data\n",
    "ul,unlabeled_set = maskfunc(Y, 10)\n",
    "label_prop_model.fit(X, ul)\n",
    "score_ten = label_prop_model.score(X, ul)\n",
    "class_report(unlabeled_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.18      0.11       935\n",
      "           1       0.25      0.28      0.26      3187\n",
      "           2       0.72      0.60      0.66      9873\n",
      "\n",
      "    accuracy                           0.50     13995\n",
      "   macro avg       0.35      0.35      0.34     13995\n",
      "weighted avg       0.57      0.50      0.53     13995\n",
      "\n",
      "Confusion matrix \n",
      " [[ 167  257  511]\n",
      " [ 520  906 1761]\n",
      " [1439 2515 5919]]\n"
     ]
    }
   ],
   "source": [
    "# 80% labelled data\n",
    "ul,unlabeled_set = maskfunc(Y, 20)\n",
    "label_prop_model.fit(X, ul)\n",
    "score_twenty = label_prop_model.score(X, ul)\n",
    "class_report(unlabeled_set,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.97      0.15      2799\n",
      "           1       0.30      0.00      0.01     10669\n",
      "           2       0.70      0.03      0.06     21518\n",
      "\n",
      "    accuracy                           0.10     34986\n",
      "   macro avg       0.36      0.34      0.07     34986\n",
      "weighted avg       0.53      0.10      0.05     34986\n",
      "\n",
      "Confusion matrix \n",
      " [[ 2719    15    65]\n",
      " [10390    53   226]\n",
      " [20721   108   689]]\n"
     ]
    }
   ],
   "source": [
    "# 50% labelled data\n",
    "ul,unlabeled_set = maskfunc(Y, 50)\n",
    "label_prop_model.fit(X, ul)\n",
    "score_fifty = label_prop_model.score(X, ul)\n",
    "class_report(unlabeled_set,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.16      5600\n",
      "           1       0.00      0.00      0.00     19598\n",
      "           2       0.84      0.00      0.00     37777\n",
      "\n",
      "    accuracy                           0.09     62975\n",
      "   macro avg       0.31      0.33      0.06     62975\n",
      "weighted avg       0.51      0.09      0.02     62975\n",
      "\n",
      "Confusion matrix \n",
      " [[ 5599     0     1]\n",
      " [19591     0     7]\n",
      " [37734     1    42]]\n"
     ]
    }
   ],
   "source": [
    "# 10% labelled data\n",
    "ul,unlabeled_set = maskfunc(Y, 90)\n",
    "label_prop_model.fit(X, ul)\n",
    "score_ninety = label_prop_model.score(X, ul)\n",
    "class_report(unlabeled_set,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.16      5937\n",
      "           1       0.00      0.00      0.00     20855\n",
      "           2       0.71      0.00      0.00     39682\n",
      "\n",
      "    accuracy                           0.09     66474\n",
      "   macro avg       0.27      0.33      0.05     66474\n",
      "weighted avg       0.43      0.09      0.01     66474\n",
      "\n",
      "Confusion matrix \n",
      " [[ 5937     0     0]\n",
      " [20853     0     2]\n",
      " [39677     0     5]]\n"
     ]
    }
   ],
   "source": [
    "# 5% labelled data\n",
    "ul,unlabeled_set = maskfunc(Y, 95)\n",
    "label_prop_model.fit(X, ul)\n",
    "score_ninetyfive = label_prop_model.score(X, ul)\n",
    "class_report(unlabeled_set,95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Spreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_spread_model = LabelSpreading(kernel='knn',gamma=20, n_neighbors=7, alpha=0.2, max_iter=30, tol=0.001, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 100 % labelled data\t 0.5794\n"
     ]
    }
   ],
   "source": [
    "label_spread_model.fit(X, Y)\n",
    "score_hundred = label_spread_model.score(X, Y)\n",
    "print('Accuracy with 100 % labelled data\\t',round(score_ten,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      1.00      0.10       384\n",
      "           1       0.00      0.00      0.00      1323\n",
      "           2       0.00      0.00      0.00      5291\n",
      "\n",
      "    accuracy                           0.05      6998\n",
      "   macro avg       0.02      0.33      0.03      6998\n",
      "weighted avg       0.00      0.05      0.01      6998\n",
      "\n",
      "Confusion matrix \n",
      " [[ 384    0    0]\n",
      " [1323    0    0]\n",
      " [5291    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#90% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 10)\n",
    "label_spread_model.fit(X, ul)\n",
    "score_ninety = label_spread_model.score(X, ul)\n",
    "class_report_spread(unlabeled_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      1.00      0.13       935\n",
      "           1       0.00      0.00      0.00      3187\n",
      "           2       0.00      0.00      0.00      9873\n",
      "\n",
      "    accuracy                           0.07     13995\n",
      "   macro avg       0.02      0.33      0.04     13995\n",
      "weighted avg       0.00      0.07      0.01     13995\n",
      "\n",
      "Confusion matrix \n",
      " [[ 935    0    0]\n",
      " [3187    0    0]\n",
      " [9873    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#80% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 20)\n",
    "label_spread_model.fit(X, ul)\n",
    "score_eighty = label_spread_model.score(X, ul)\n",
    "class_report_spread(unlabeled_set,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      1.00      0.15      2799\n",
      "           1       0.00      0.00      0.00     10669\n",
      "           2       1.00      0.00      0.00     21518\n",
      "\n",
      "    accuracy                           0.08     34986\n",
      "   macro avg       0.36      0.33      0.05     34986\n",
      "weighted avg       0.62      0.08      0.01     34986\n",
      "\n",
      "Confusion matrix \n",
      " [[ 2799     0     0]\n",
      " [10669     0     0]\n",
      " [21517     0     1]]\n"
     ]
    }
   ],
   "source": [
    "#50% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 50)\n",
    "label_spread_model.fit(X, ul)\n",
    "score_fifty = label_spread_model.score(X, ul)\n",
    "class_report_spread(unlabeled_set,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.16      5600\n",
      "           1       0.00      0.00      0.00     19598\n",
      "           2       1.00      0.00      0.00     37777\n",
      "\n",
      "    accuracy                           0.09     62975\n",
      "   macro avg       0.36      0.33      0.05     62975\n",
      "weighted avg       0.61      0.09      0.01     62975\n",
      "\n",
      "Confusion matrix \n",
      " [[ 5600     0     0]\n",
      " [19598     0     0]\n",
      " [37773     0     4]]\n"
     ]
    }
   ],
   "source": [
    "#10% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 90)\n",
    "label_spread_model.fit(X, ul)\n",
    "score_ten = label_spread_model.score(X, ul)\n",
    "class_report_spread(unlabeled_set,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.16      5937\n",
      "           1       0.00      0.00      0.00     20855\n",
      "           2       0.71      0.00      0.00     39682\n",
      "\n",
      "    accuracy                           0.09     66474\n",
      "   macro avg       0.27      0.33      0.05     66474\n",
      "weighted avg       0.43      0.09      0.01     66474\n",
      "\n",
      "Confusion matrix \n",
      " [[ 5937     0     0]\n",
      " [20853     0     2]\n",
      " [39677     0     5]]\n"
     ]
    }
   ],
   "source": [
    "#5% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 95)\n",
    "label_spread_model.fit(X, ul)\n",
    "score_five = label_spread_model.score(X, ul)\n",
    "class_report_spread(unlabeled_set,95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 100 % labelled data\t 0.65\n"
     ]
    }
   ],
   "source": [
    "#100% Labelled Data\n",
    "knn_model.fit(X, Y)\n",
    "score_0 = knn_model.score(X, Y)\n",
    "print('Accuracy with 100 % labelled data\\t',round(score_0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 90 % labelled data\t 0.5946\n"
     ]
    }
   ],
   "source": [
    "#90% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 10)\n",
    "knn_model.fit(X, ul)\n",
    "score_10 = knn_model.score(X, ul)\n",
    "print('Accuracy with 90 % labelled data\\t',round(score_10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 80 % labelled data\t 0.5637\n"
     ]
    }
   ],
   "source": [
    "#80% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 20)\n",
    "knn_model.fit(X, ul)\n",
    "score_20 = knn_model.score(X, ul)\n",
    "print('Accuracy with 80 % labelled data\\t',round(score_20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 50 % labelled data\t 0.6341\n"
     ]
    }
   ],
   "source": [
    "#50% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 50)\n",
    "knn_model.fit(X, ul)\n",
    "score_50 = knn_model.score(X, ul)\n",
    "print('Accuracy with 50 % labelled data\\t',round(score_50,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 10 % labelled data\t 0.9013\n"
     ]
    }
   ],
   "source": [
    "#10% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 90)\n",
    "knn_model.fit(X, ul)\n",
    "score_90 = knn_model.score(X, ul)\n",
    "print('Accuracy with 10 % labelled data\\t',round(score_90,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 5 % labelled data\t 0.9501\n"
     ]
    }
   ],
   "source": [
    "#5% Labelled Data\n",
    "ul,unlabeled_set = maskfunc(Y, 95)\n",
    "knn_model.fit(X, ul)\n",
    "score_95 = knn_model.score(X, ul)\n",
    "print('Accuracy with 5 % labelled data\\t',round(score_95,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
